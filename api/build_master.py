#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Builds a single "master" bundle from all useful repo outputs so you can upload
just one file (or point an external consumer at one URL).

Outputs:
  - api/master.json     (one big JSON dict)
  - api/master.ndjson   (line-delimited objects for streaming / RAG)

What it tries to collect (all optional; missing files are skipped):
  API snapshots:
    - api/events.json
    - api/events_upcoming_30d.json
    - api/features.json
    - api/balance.json
    - api/wiki.json

  Canonical tables (CSV/JSON):
    - POGO_Digest.json / POGO_Digest.csv
    - POGO_Balance.json / POGO_Balance.csv
    - POGO_Features.json / POGO_Features.csv
    - POGO_Wiki_Library.json

  Libraries & indices (for RAG / auditing):
    - pogo_library/events/index.json, index.ndjson
    - pogo_library/features/index.json, index.ndjson
    - pogo_library/balance/index.json, index.ndjson
    - pogo_library/wiki/index.json, index.ndjson

  Calendar (raw ICS text and a simple file hash)
    - POGO_Events.ics
"""

import os, json, csv, hashlib, time
from typing import Any, Dict, List, Optional

# ---------- helpers

def now_iso() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

def read_text(path: str) -> Optional[str]:
    if not os.path.isfile(path):
        return None
    with open(path, "r", encoding="utf-8", errors="replace") as f:
        return f.read()

def load_json(path: str) -> Optional[Any]:
    if not os.path.isfile(path):
        return None
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def load_csv(path: str) -> Optional[List[Dict[str, Any]]]:
    if not os.path.isfile(path):
        return None
    rows: List[Dict[str, Any]] = []
    with open(path, "r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        for row in reader:
            rows.append(dict(row))
    return rows

def file_info(path: str) -> Optional[Dict[str, Any]]:
    if not os.path.isfile(path):
        return None
    st = os.stat(path)
    sha = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            sha.update(chunk)
    return {
        "path": path,
        "size_bytes": st.st_size,
        "sha256": sha.hexdigest(),
        "modified": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(st.st_mtime)),
    }

def first_of(*candidates: str) -> Optional[str]:
    for p in candidates:
        if os.path.isfile(p):
            return p
    return None

def ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)

def add_if_present(bundle: Dict[str, Any], key: str, data: Any) -> None:
    if data is not None:
        bundle[key] = data

def ndjson_dump(path: str, records: List[Dict[str, Any]]) -> None:
    with open(path, "w", encoding="utf-8") as f:
        for r in records:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

# ---------- collection

def collect_bundle() -> Dict[str, Any]:
    root_meta = {
        "generated_at": now_iso(),
        "git_sha": os.environ.get("GITHUB_SHA"),
        "run_id": os.environ.get("GITHUB_RUN_ID"),
        "run_number": os.environ.get("GITHUB_RUN_NUMBER"),
        "notes": "Master bundle generated by api/build_master.py",
    }

    bundle: Dict[str, Any] = {"_meta": root_meta}

    # API snapshots
    add_if_present(bundle, "api_events",             load_json("api/events.json"))
    add_if_present(bundle, "api_events_upcoming_30d",load_json("api/events_upcoming_30d.json"))
    add_if_present(bundle, "api_features",           load_json("api/features.json"))
    add_if_present(bundle, "api_balance",            load_json("api/balance.json"))
    add_if_present(bundle, "api_wiki",               load_json("api/wiki.json"))

    # Canonical tables (JSON beats CSV; CSV used as fallback)
    # Events (digest)
    events_json = load_json("POGO_Digest.json")
    if events_json is None:
        events_json = load_csv("POGO_Digest.csv")
    add_if_present(bundle, "table_events", events_json)

    # Features
    feats_json = load_json("POGO_Features.json")
    if feats_json is None:
        feats_json = load_csv("POGO_Features.csv")
    add_if_present(bundle, "table_features", feats_json)

    # Balance
    balance_json = load_json("POGO_Balance.json")
    if balance_json is None:
        balance_json = load_csv("POGO_Balance.csv")
    add_if_present(bundle, "table_balance", balance_json)

    # Wiki library (JSON only)
    add_if_present(bundle, "table_wiki_library", load_json("POGO_Wiki_Library.json"))

    # RAG-friendly libraries (JSON lists + we keep pointers to NDJSON files)
    add_if_present(bundle, "lib_events",   load_json("pogo_library/events/index.json"))
    add_if_present(bundle, "lib_features", load_json("pogo_library/features/index.json"))
    add_if_present(bundle, "lib_balance",  load_json("pogo_library/balance/index.json"))
    add_if_present(bundle, "lib_wiki",     load_json("pogo_library/wiki/index.json"))

    # NDJSON file metadata (so a downstream consumer can fetch them if needed)
    ndjson_meta = {
        "events":  file_info("pogo_library/events/index.ndjson"),
        "features":file_info("pogo_library/features/index.ndjson"),
        "balance": file_info("pogo_library/balance/index.ndjson"),
        "wiki":    file_info("pogo_library/wiki/index.ndjson"),
    }
    # Only add keys that exist
    ndjson_meta = {k: v for k, v in ndjson_meta.items() if v is not None}
    if ndjson_meta:
        bundle["ndjson_indices"] = ndjson_meta

    # Calendar: raw ICS text + a file hash (we donâ€™t parse ICS here to avoid extra deps)
    ics_path = first_of("POGO_Events.ics", "outputs/latest/POGO_Events.ics")
    if ics_path:
        add_if_present(bundle, "calendar_ics", read_text(ics_path))
        add_if_present(bundle, "calendar_ics_info", file_info(ics_path))

    # Lightweight summary counts
    summary = {}
    for key in ("api_events","api_events_upcoming_30d","api_features","api_balance","api_wiki",
                "table_events","table_features","table_balance","table_wiki_library",
                "lib_events","lib_features","lib_balance","lib_wiki"):
        val = bundle.get(key)
        if isinstance(val, list):
            summary[key + "_count"] = len(val)
        elif isinstance(val, dict):
            # common API shapes use {"data": [...]}
            if "data" in val and isinstance(val["data"], list):
                summary[key + "_count"] = len(val["data"])
    if summary:
        bundle["_summary"] = summary

    return bundle

# ---------- write

def write_outputs(bundle: Dict[str, Any]) -> None:
    ensure_dir("api")
    # master.json
    with open("api/master.json", "w", encoding="utf-8") as f:
        json.dump(bundle, f, ensure_ascii=False, indent=2)

    # master.ndjson: flatten into several streams that are likely useful for search/RAG
    records: List[Dict[str, Any]] = []
    def push(stream: str, item: Dict[str, Any]) -> None:
        rec = dict(item)
        rec["_stream"] = stream
        records.append(rec)

    # choose common lists if present
    if isinstance(bundle.get("table_events"), list):
        for r in bundle["table_events"]:
            push("events", r)
    if isinstance(bundle.get("table_features"), list):
        for r in bundle["table_features"]:
            push("features", r)
    if isinstance(bundle.get("table_balance"), list):
        for r in bundle["table_balance"]:
            push("balance", r)
    if isinstance(bundle.get("table_wiki_library"), list):
        for r in bundle["table_wiki_library"]:
            push("wiki", r)

    # also include lib_* (usually richer but noisier)
    if isinstance(bundle.get("lib_events"), list):
        for r in bundle["lib_events"]:
            push("lib_events", r)
    if isinstance(bundle.get("lib_features"), list):
        for r in bundle["lib_features"]:
            push("lib_features", r)
    if isinstance(bundle.get("lib_balance"), list):
        for r in bundle["lib_balance"]:
            push("lib_balance", r)
    if isinstance(bundle.get("lib_wiki"), list):
        for r in bundle["lib_wiki"]:
            push("lib_wiki", r)

    ndjson_dump("api/master.ndjson", records)

# ---------- main

def main() -> None:
    bundle = collect_bundle()
    write_outputs(bundle)
    print("Wrote api/master.json and api/master.ndjson")

if __name__ == "__main__":
    main()